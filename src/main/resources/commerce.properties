#jdbc设置
jdbc.datasource.size=10
jdbc.url=jdbc:mysql://bd1:3306/commerce
jdbc.user=root
jdbc.password=root
jdbc.session_aggr_stat_table_name=session_aggr_stat
jdbc.session_random_extract_table_name=session_random_extract
jdbc.session_detail_table_name=session_detail
jdbc.top10_category_table_name=top10_category
jdbc.top10_session_table_name=top10_session

# 可以使用的属性如下：
#      startDate： 格式： yyyy-MM-DD   [必选]
#      endDate:    格式： yyyy-MM-DD   [必选]
#      startAge:   范围： 0 - 59
#      endAge:     范围： 0 - 59
#      professionals： 范围：professionals[0 - 100]
#      cities:     0 - 100  ((0,"北京","华北"),(1,"上海","华东"),(2,"南京","华东"),(3,"广州","华南"),(4,"三亚","华南"),(5,"武汉","华中"),(6,"长沙","华中"),(7,"西安","西北"),(8,"成都","西南"),(9,"哈尔滨","东北"))
#      sex:        范围： male.female
#      keywords:   范围： ("火锅", "蛋糕", "重庆辣子鸡", "重庆小面", "呷哺呷哺", "新辣道鱼火锅", "国贸大厦", "太古商场", "日本料理", "温泉")
#      categoryIds：0 - 99，以逗号分隔
#      targetPageFlow： 0 - 99， 以逗号分隔
##task.params.json  是后面要用到的过滤条件,在该程序中，我们没有使用过滤条件
task.params.json=\
  {startDate:"2020-01-01", \
  endDate:"2020-01-30", \
  startAge: 0, \
  endAge: 59, \
  professionals: "professional0,professional1,professional2,professional3,professional4,professional5,professional6,professional7,professional8",  \
  cities: "city0,city1,city2,city3,city4,city5,city6,city8,city9,city10,city11,city12,city13,city14,city15,city16", \
  sex:"male,female", \
  keywords:"", \
  categoryIds:"0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20", \
  targetPageFlow:"0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20"}

kafka.broker.list=bd1:9092,bd2:9092,bd3:9092
kafka.topics=AdRealTimeLog